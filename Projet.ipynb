{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Partie 1 : Importation des bibliothèques et préparation des données\n",
    "On commence par modulariser le code, en créant des fonctions pour des tâches spécifiques et en utilisant des paramètres pour rendre le code plus flexible.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Importation des bibliothèques nécessaires\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Dropout\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Définir les équipes Euro et Copa une seule fois\n",
    "euro_teams = [\n",
    "    'Albania', 'Germany', 'England', 'Austria', 'Belgium', 'Croatia', 'Denmark',\n",
    "    'Scotland', 'Spain', 'France', 'Georgia', 'Hungary', 'Italy', 'Netherlands',\n",
    "    'Poland', 'Portugal', 'Romania', 'Serbia', 'Slovakia', 'Slovenia', 'Switzerland',\n",
    "    'Czech Republic', 'Turkey', 'Ukraine'\n",
    "]\n",
    "\n",
    "copa_teams = [\n",
    "    'Argentina', 'Peru', 'Chile', 'Brazil', 'United States', 'Colombia', 'Canada',\n",
    "    'Mexico', 'Jamaica', 'Venezuela', 'Ecuador', 'Paraguay', 'Costa Rica',\n",
    "    'Uruguay', 'Panama', 'Bolivia'\n",
    "]\n",
    "\n",
    "# Fonction pour charger et filtrer les données\n",
    "def load_and_filter_data(file_path, euro_teams, copa_teams, start_date='2016-01-01'):\n",
    "    df = pd.read_csv(file_path)\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    \n",
    "    # Filtrer les matchs impliquant des équipes Euro ou Copa\n",
    "    df_filtered = df[df['date'] >= start_date]\n",
    "    df_filtered = df_filtered[(df_filtered['home_team'].isin(euro_teams + copa_teams)) |\n",
    "                              (df_filtered['away_team'].isin(euro_teams + copa_teams))]\n",
    "    \n",
    "    # Créer une colonne de résultat : 0 (défaite), 1 (égalité), 2 (victoire)\n",
    "    df_filtered['result'] = np.where(df_filtered['home_score'] > df_filtered['away_score'], 2,\n",
    "                                     np.where(df_filtered['home_score'] == df_filtered['away_score'], 1, 0))\n",
    "    \n",
    "    return df_filtered\n",
    "\n",
    "# Charger les données\n",
    "file_path = '/content/drive/MyDrive/22102/results.csv'\n",
    "df_filtered = load_and_filter_data(file_path, euro_teams, copa_teams)\n",
    "\n",
    "# Afficher un aperçu des données filtrées\n",
    "df_filtered.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modularisation : La fonction load_and_filter_data permet de filtrer les données en fonction des équipes Euro/Copa et d'ajouter une colonne pour le résultat du match. Cela évite la répétition de code et rend le script plus clair.\n",
    "Paramétrisation : Le chemin du fichier et la date de début sont passés en paramètres, ce qui rend le code plus flexible.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Partie 2 : Préparation des données pour le modèle LSTM\n",
    "Ici, nous créons une fonction pour construire les séquences de données nécessaires à l'entraînement du modèle LSTM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Fonction pour créer des séquences de matchs\n",
    "def build_sequences(df, teams):\n",
    "    sequences = {}\n",
    "    for team in teams:\n",
    "        # Séparer les matchs à domicile et à l'extérieur\n",
    "        home_matches = df[df['home_team'] == team]['result'].values\n",
    "        away_matches = df[df['away_team'] == team]['result'].values\n",
    "        # Concaténer les séquences\n",
    "        sequences[team] = np.concatenate((home_matches, away_matches))\n",
    "    return sequences\n",
    "\n",
    "# Créer des séquences pour les données d'entraînement et de test\n",
    "train_data, test_data = train_test_split(df_filtered, test_size=0.2, shuffle=True, random_state=42)\n",
    "train_sequences = build_sequences(train_data, euro_teams + copa_teams)\n",
    "test_sequences = build_sequences(test_data, euro_teams + copa_teams)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La fonction build_sequences crée des séquences pour chaque équipe en combinant les résultats des matchs à domicile et à l'extérieur. Cela permet de passer ensuite ces séquences à un modèle LSTM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Partie 3 : Préparation des données d'entrée pour le modèle\n",
    "Ensuite, nous préparons les données d'entraînement et de test en utilisant les séquences construites précédemment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Fonction pour préparer les données pour le modèle LSTM\n",
    "def prepare_data(sequences, sequence_length):\n",
    "    X, y = [], []\n",
    "    for team, sequence in sequences.items():\n",
    "        for i in range(len(sequence) - sequence_length):\n",
    "            X.append(sequence[i:i+sequence_length])\n",
    "            y.append(sequence[i+sequence_length])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# Définir la longueur de la séquence\n",
    "sequence_length = 10\n",
    "\n",
    "# Préparer les données pour l'entraînement et le test\n",
    "X_train, y_train = prepare_data(train_sequences, sequence_length)\n",
    "X_test, y_test = prepare_data(test_sequences, sequence_length)\n",
    "\n",
    "# Reshaper les données pour le LSTM\n",
    "X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modularisation : La fonction prepare_data permet de transformer les séquences en entrées et sorties exploitables par le modèle LSTM.\n",
    "Reshape des données : Comme le modèle LSTM prend des entrées sous forme de séquences tridimensionnelles (nombre de séquences, longueur des séquences, 1 caractéristique), les données sont mises en forme en conséquence.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Partie 4 : Construction et entraînement du modèle LSTM\n",
    "Nous construisons ensuite le modèle LSTM avec plusieurs couches de LSTM et de Dropout, comme dans ton code initial, mais ici, j'ajoute une amélioration des hyperparamètres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Fonction pour construire le modèle LSTM\n",
    "def build_lstm_model(input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units=64, return_sequences=True, input_shape=input_shape))\n",
    "    model.add(Dropout(0.3))  # Légèrement augmenté pour réduire le sur-apprentissage\n",
    "    model.add(LSTM(units=64, return_sequences=True))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(LSTM(units=64))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(units=3, activation='softmax'))  # 3 classes de sortie (défaite, égalité, victoire)\n",
    "    \n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Construire et entraîner le modèle\n",
    "model = build_lstm_model((X_train.shape[1], 1))\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "# Évaluation du modèle\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(\"Accuracy du modèle sur les données de test :\", accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparamètres : J'ai augmenté les unités LSTM de 50 à 64 et le taux de Dropout de 0.2 à 0.3 pour améliorer la robustesse du modèle. Ce sont des valeurs que tu peux ajuster selon les performances observées.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Partie 5 : Évaluation du modèle\n",
    "En plus de l'accuracy, je te propose d'ajouter un rapport de classification pour mieux évaluer les résultats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Prédictions sur les données de test\n",
    "y_pred = np.argmax(model.predict(X_test), axis=1)\n",
    "\n",
    "# Rapport de classification\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification Report : Cette fonction fournit des informations détaillées sur la précision, le rappel, et le F1-score, qui sont des métriques essentielles pour évaluer un modèle de classification multiclasses.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
